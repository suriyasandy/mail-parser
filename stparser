import extract_msg
import re
import io
from bs4 import BeautifulSoup
import pandas as pd
from PIL import Image
import easyocr
from parsers.table_extractor import extract_plaintext_tables  # your existing function

# instantiate the OCR reader once
reader = easyocr.Reader(['en'], gpu=False)

def parse_msg_file_categorized(file_path: str) -> dict:
    """
    Parses a .msg file and returns:
      - subject
      - text_body
      - html_body
      - inline_images (list of {filename, data})
      - image_attachments (list of {filename, data})
      - ocr_results (list of {filename, text or error})
      - html_tables (list of DataFrames)
      - plaintext_tables (list of DataFrames)
    """
    msg = extract_msg.Message(file_path)
    msg.encoding = 'utf-8'

    subject   = msg.subject or ""
    text_body = msg.body    or ""
    html_body = msg.htmlBody or msg.html_body or ""

    # separate inline vs attachment images
    inline_images    = []
    image_attachments = []
    for att in msg.attachments or []:
        name = att.longFilename or att.shortFilename or ""
        data = att.data
        ext  = name.lower().split('.')[-1]
        if ext in ("png","jpg","jpeg","bmp","tiff"):
            # treat as inline if referenced by CID in html
            cid_ref = f"cid:{name}"
            if hasattr(att, "content_id") or cid_ref in html_body:
                inline_images.append({"filename": name, "data": data})
            else:
                image_attachments.append({"filename": name, "data": data})

    # run OCR on all attachment images
    ocr_results = []
    for img in image_attachments:
        try:
            # you can also do Image.open(io.BytesIO(img["data"])) if needed
            texts = reader.readtext(img["data"], detail=0)
            ocr_results.append({
                "filename": img["filename"],
                "text": "\n".join(texts)
            })
        except Exception as e:
            ocr_results.append({
                "filename": img["filename"],
                "error": str(e)
            })

    # extract HTML tables
    soup = BeautifulSoup(html_body, "html.parser")
    html_tables = []
    for table in soup.find_all("table"):
        try:
            df = pd.read_html(str(table))[0]
            html_tables.append(df)
        except Exception:
            continue

    # extract plaintext tables
    plaintext_tables = extract_plaintext_tables(text_body)

    return {
        "subject": subject,
        "text_body": text_body,
        "html_body": html_body,
        "inline_images": inline_images,
        "image_attachments": image_attachments,
        "ocr_results": ocr_results,
        "html_tables": html_tables,
        "plaintext_tables": plaintext_tables,
    }
