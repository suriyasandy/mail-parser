from parsers.msg_parser import parse_msg_file_categorized
from nlp.sentence_splitter import clean_and_split_sentences
from nlp.attribute_extractor import extract_attributes
from parsers.table_parser import extract_table_like_data
from nlp.spacy_extractor import extract_with_spacy
from parsers.image_table_parser import run_easyocr_and_parse_table
from tracker.entity_mapper import merge_entity_data


def main(file_path: str):
    user_fields = ["Trade Ref", "RoRWA", "VA", "RCVA", "CVA", "FVA", "PnL", "Trade Id", "BUI Value", "COB Date", "Trade Date"]
    
    # Step 1: Categorized parsing of msg file
    parsed = parse_msg_file_categorized(file_path)

    # Step 2: Textual processing
    full_text = parsed["text_body"] + "\n" + parsed["html_body"]
    sentences = clean_and_split_sentences(full_text)
    regex_data = extract_attributes(sentences, user_fields)
    spacy_data = extract_with_spacy(full_text, user_fields)
    table_data = extract_table_like_data(full_text.splitlines(), user_fields)

    # Step 3: Image OCR + Table parsing
    ocr_data = []
    for img_bytes in parsed["image_attachments"]:
        ocr_rows = run_easyocr_and_parse_table(img_bytes)
        ocr_data.extend(ocr_rows)

    # Step 4: Merge all extracted info
    merged = merge_entity_data(
        sentence_data=regex_data,
        table_data=table_data,
        spacy_data=spacy_data,
        ocr_table_data=ocr_data,
        default_entity="GLOBAL"
    )

    # Step 5: Print results
    print("\n==== FINAL STRUCTURED OUTPUT ====\n")
    for entity, attrs in merged.items():
        print(f"Entity: {entity}")
        for attr, values in attrs.items():
            print(f"  {attr}: {values}")


if __name__ == "__main__":
    file_path = "data/sample1.msg"  # Update to your local file
    main(file_path)
